{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from multiprocessing import set_start_method\n",
    "#set_start_method(\"spawn\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.distributed import *\n",
    "from fastai2.data.transforms import *\n",
    "from fastai2.vision.all import *\n",
    "import gc\n",
    "from itertools import product\n",
    "from scipy import signal\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "rcParams['figure.dpi'] = 300\n",
    "rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_SIZE      = 500_000 \n",
    "TEST_SEGMENT_SIZE = 100_000\n",
    "\n",
    "WINDOW_SIZE = 1000\n",
    "BS = max(1,torch.cuda.device_count()) * 192\n",
    "HIST_BINS = 128\n",
    "SPLITS = 5\n",
    "XTRA_DS = False\n",
    "\n",
    "FEAT_WINDOW = 1\n",
    "\n",
    "assert SEGMENT_SIZE % WINDOW_SIZE == 0\n",
    "assert (SEGMENT_SIZE // WINDOW_SIZE) % SPLITS == 0\n",
    "SEED = 321\n",
    "DATA_SUFFIX = '_clean'\n",
    "\n",
    "p_input = Path('input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_dtypes = {'time': np.float32, 'signal': np.float32, 'open_channels': np.int32 }\n",
    "test_dtypes  = {'time': np.float32, 'signal': np.float32 }\n",
    "df_train  = pd.read_csv(p_input / f'train.csv', dtype= train_dtypes)\n",
    "df_test   = pd.read_csv(p_input / f'test.csv',  dtype= test_dtypes)\n",
    "df_train_drift = pd.read_csv(p_input / f'train{DATA_SUFFIX}.csv', dtype= train_dtypes)\n",
    "df_test_drift  = pd.read_csv(p_input / f'test{DATA_SUFFIX}.csv',  dtype= test_dtypes)\n",
    "sub   = pd.read_csv(p_input / 'sample_submission.csv',  dtype={'time': np.float32})\n",
    "df_train['drift'] = df_train['signal'] - df_train_drift['signal']\n",
    "df_test['drift']  = df_test['signal']  - df_test_drift['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['signal'] =  df_train_drift['signal']\n",
    "df_test['signal']  =   df_test_drift['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['open_channels'][2300000:2400000][(df_train['open_channels'][2300000:2400000]==0)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_xtra_csvs = {\n",
    "    1: ['outfinaltest10.csv',  'outfinaltest44.csv',],#  'outfinaltest78.csv',],  'outfinaltest10.csv',  'outfinaltest44.csv'],\n",
    "    3: ['outfinaltest1.csv',   'outfinaltest2.csv',   'outfinaltest3.csv',   'outfinaltest4.csv', 'outfinaltest5.csv'],\n",
    "    5: ['outfinaltest328.csv', 'outfinaltest534.csv', 'outfinaltest747.csv',]#, 'outfinaltest328.csv', 'outfinaltest534.csv']\n",
    "}\n",
    "\n",
    "df_train_xtra = None\n",
    "for _,xtra_csvs in d_xtra_csvs.items():\n",
    "    for xtra_csv in xtra_csvs:\n",
    "        xx = pd.read_csv(p_input / xtra_csv , header=None,names=['time', 'signal', 'open_channels'])\n",
    "        df_train_xtra = pd.concat((xx,df_train_xtra), axis=0)\n",
    "df_train_xtra['drift']  = 0.\n",
    "if XTRA_DS: df_train = pd.concat((df_train,df_train_xtra), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.cat((torch.FloatTensor(df_train['signal'        ].values).unsqueeze(0),\n",
    "                   #torch.FloatTensor(df_train['drift'         ].values).unsqueeze(0),\n",
    "                   torch.FloatTensor(df_train['open_channels' ].values).unsqueeze(0)))\n",
    "test  = torch.cat((torch.FloatTensor(df_test ['signal'        ].values).unsqueeze(0),\n",
    "                   #torch.FloatTensor(df_test ['drift'         ].values).unsqueeze(0)\n",
    "                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean  = np.load(str(p_input / 'test_x_without50hz.npy'))\n",
    "train_clean = np.load(str(p_input / 'train_x_without50hz.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_clean.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_clean.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0,:] = Tensor(train_clean)\n",
    "test[0,:]  = Tensor(test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_synth = Path('synth')\n",
    "use_memmap = True\n",
    "load_fn = np.load if not use_memmap else partial(np.lib.format.open_memmap, mode='r')\n",
    "\n",
    "try:\n",
    "    high = load_fn(str(p_synth / 'high.npy'))\n",
    "    low  = load_fn(str(p_synth / 'low.npy'))\n",
    "except:\n",
    "    high   = pd.read_csv(p_synth / 'high.csv',header=None).values.astype('uint8')\n",
    "    low    = pd.read_csv(p_synth /  'low.csv',header=None).values.astype('uint8')\n",
    "    np.save(str(p_synth / 'high.npy'), high)\n",
    "    np.save(str(p_synth /  'low.npy'),  low)\n",
    "high = high.reshape(-1,SEGMENT_SIZE)\n",
    "low  =  low.reshape(-1,SEGMENT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synth_segment_y(states,max_channels,size=SEGMENT_SIZE):\n",
    "    y = torch.zeros((size,),dtype=torch.uint8)\n",
    "    states = {'l':low, 'h':high }[states]\n",
    "    for ii,i in enumerate(np.random.choice(states.shape[0],max_channels,replace=False)):\n",
    "        o = np.random.randint(1+max(0,SEGMENT_SIZE-size))\n",
    "        y += states[i,o:o+size]\n",
    "    return y.clamp(0, 10)\n",
    "y=get_synth_segment_y('h',10,SEGMENT_SIZE)\n",
    "np.bincount(y,minlength=11)\n",
    "# (low,1), (low,1), (high,1), (high,3), (high,10), (high,5), (high,1), (high,3), (high,5), (high,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): print(np.bincount(get_synth_segment_y('l',5,SEGMENT_SIZE//5),minlength=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -0.12838999,49.9232689,1.73201717\n",
    "\n",
    "test_std_by_type = {('l', 3): [0.23856227099895477,\n",
    "              0.2386934608221054,\n",
    "              0.23847833275794983,\n",
    "              0.23833979666233063,\n",
    "              0.24214892089366913,\n",
    "              0.24653472006320953,\n",
    "              0.2441188395023346],\n",
    "             ('h', 3): [0.2698204517364502, 0.2679280936717987],\n",
    "             ('h', 5): [0.27920418977737427, 0.27736446261405945],\n",
    "             ('l', 4): [0.23756568133831024,\n",
    "              0.24620571732521057,\n",
    "              0.24222536385059357],\n",
    "             ('h', 1): [0.2443782091140747],\n",
    "             ('h', 10): [0.3530166447162628, 0.3537397086620331],\n",
    "             ('l', 2): [0.23785734176635742,\n",
    "              0.2443142682313919,\n",
    "              0.24280819296836853]}\n",
    "\n",
    "train_std_by_type = {('l', 1): [0.24515989422798157, 0.24703997373580933],\n",
    "             ('h', 1): [0.24486009776592255, 0.2447292059659958],\n",
    "             ('h', 3): [0.265836238861084],\n",
    "             ('h', 10): [0.4045635759830475, 0.40377894043922424],\n",
    "             ('h', 5): [0.28642651438713074, 0.28378984332084656]}\n",
    "\n",
    "def get_synth_segment_xy(states,max_channels,size=SEGMENT_SIZE,add_ac=False,y=None,add_noise=True,add_bias=True):\n",
    "    kernel = tensor([-1.6590e-03, -1.1617e-04, -1.0344e-03,  8.4467e-04, -9.7054e-04,\n",
    "              1.4413e-03,  6.5739e-03,  2.8979e-02,  1.2115e+00, -1.0717e-03,\n",
    "             -3.8138e-03,  6.0101e-04,  1.2317e-04,  3.1660e-03, -8.8741e-04,\n",
    "              3.2797e-04,  2.5820e-03, -2.3032e-03])\n",
    "    dim_k = kernel.numel()\n",
    "    if max_channels is None: max_channels = y.max()\n",
    "    bias = tensor([-5.5336 if max_channels >= 10 else -2.7708])\n",
    "    if y is None: y = get_synth_segment_y(states,max_channels,size)\n",
    "    y_padded = torch.zeros(y.shape[0]+dim_k-1)\n",
    "    cc = (dim_k-1)//2\n",
    "    y_padded[cc:cc+y.shape[0]] = y.float()\n",
    "    y_padded = y_padded.view(1,1,-1)\n",
    "    x = (F.conv1d(y_padded,kernel.view(1,1,-1)).flatten() + bias).to(y.device)\n",
    "    if add_noise:\n",
    "        if add_ac:\n",
    "            ac_weight,ac_freq,ac_phase = -0.12838999,50+0.2*(torch.rand(1)-0.5),2*math.pi*torch.rand(1)\n",
    "            x_range = torch.arange(x.shape[0]).float().to(x.device)\n",
    "            wave = (ac_weight * torch.sin( x_range * 2*math.pi/10000 * ac_freq + ac_phase))\n",
    "            x += wave\n",
    "        max_channels = min(max_channels,10)\n",
    "        std_by_type = train_std_by_type if (states,max_channels) in train_std_by_type else test_std_by_type\n",
    "        std = np.random.choice(std_by_type[(states,max_channels)])\n",
    "        x += std * torch.randn(x.numel()).to(x.device)\n",
    "        if add_bias: x += 0.4*(2*torch.rand(1)-1)\n",
    "    return x.unsqueeze(-1),y.unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[-1].view(-1,SEGMENT_SIZE)[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from fastai2.text.models.qrnn import QRNN\n",
    "class Synthetizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        f_out = 16\n",
    "\n",
    "        self.QRNN = QRNN(input_size=FEAT_WINDOW, hidden_size=f_out, n_layers=3, batch_first=True, \n",
    "                          window=2, bidirectional=True, dropout=0.)\n",
    "        self.LSTM  = nn.LSTM(input_size=f_out*2, hidden_size=f_out, num_layers=1, batch_first=True, \n",
    "                            bidirectional=True, dropout=0.)\n",
    "        self.fc = nn.Sequential(nn.Linear(f_out*2,  f_out),    Swish(), \n",
    "                                nn.Linear(f_out,    f_out//2), Swish(),\n",
    "                                nn.Linear(f_out//2, 1))\n",
    "        \n",
    "        k,p = (3,1), (1,0)\n",
    "        self.convs = nn.Sequential(\n",
    "            ConvLayer( 1,32,k,padding=p), ConvLayer(32,32,k,padding=p), ConvLayer(32,32,k,padding=p),\n",
    "            ConvLayer(32,32,k,padding=p), ConvLayer(32,32,k,padding=p), ConvLayer(32,f_out*2,k,padding=p))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        n_pad = 48\n",
    "        x = nn.ReplicationPad1d(n_pad)(x.permute(0,2,1)).permute(0,2,1)#.unsqueeze(-1)\n",
    "        x,_ = self.QRNN(x) # bs,16\n",
    "        #hc = hc[-1].unsqueeze(-1).expand(-1,-1,x.shape[1])\n",
    "        #x = self.convs(x.permute(0,2,1).unsqueeze(-1)).squeeze(-1)\n",
    "        #x = torch.cat((hc,x),dim=1).permute(0,2,1)\n",
    "#        x, _ = self.LSTM(x)\n",
    "        return self.fc(x)[:,n_pad:-n_pad]\n",
    "synth = Synthetizer()\n",
    "p='models/y_to_x_qrnn7297_t36000_v9_BS40_SS500000_WS100000_FW1_cv0.089554_clean_clean50hz.pth'\n",
    "synth.load_state_dict(torch.load(p)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "segment = [4,9]\n",
    "s = train.view(2,-1,SEGMENT_SIZE)[:,segment,:]\n",
    "x,y=s[0].flatten(),s[-1].flatten()\n",
    "print(x.shape)\n",
    "x_pred_naive = get_synth_segment_xy(None,10,y=y,add_noise=False)[0].flatten()\n",
    "synth.eval().cuda()\n",
    "with torch.no_grad(): x_pred_nn = synth(y.view(1,-1,1).cuda()).flatten().cpu()\n",
    "#plt.plot(x)\n",
    "plt.plot(x_pred_naive)\n",
    "plt.plot(x_pred_nn)\n",
    "((x-x_pred_naive)**2).sum(),((x-x_pred_nn)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types = [('l', 3), ('h', 3), ('h', 5), ('l', 4), ('h', 1), ('h', 10), ('h', 5), ('h', 10), ('l', 3), ('h', 3),\n",
    "              ('l', 3), ('l', 3), ('l', 2), ('l', 4), ('l', 4), ('l',  3), ('l', 3), ('l',  2), ('l', 2), ('l', 3)]\n",
    "\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "test_types_x3 = flatten((i,i,i) for i in test_types)\n",
    "public_types  = test_types_x3[:len(test_types)]\n",
    "private_types = test_types_x3[len(test_types):]\n",
    "\n",
    "public_s = np.nan * torch.empty(2,len(public_types),TEST_SEGMENT_SIZE,1)\n",
    "for i,segment in enumerate(public_types): \n",
    "    public_s[0,i],public_s[-1,i]= get_synth_segment_xy(*segment,TEST_SEGMENT_SIZE)\n",
    "plt.plot(public_s[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_s = np.nan * torch.empty(2,len(private_types),TEST_SEGMENT_SIZE,1)\n",
    "for i,segment in enumerate(private_types): \n",
    "    private_s[0,i],private_s[-1,i]= get_synth_segment_xy(*segment,TEST_SEGMENT_SIZE)\n",
    "plt.plot(private_s[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = parallel(lambda x:get_synth_segment_xy(*x), private_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_types=flatten([[('l', 1),('l', 2), ('l', 3), ('l', 4)],\n",
    "             [('h',1)]*10,\n",
    "             [('h', 3)]*20,\n",
    "             [('h', 5)]*20,\n",
    "             [('h', 10)]*60,]) * 10\n",
    "\n",
    "train_types = [('l', 1),('l', 1),('h', 1),('h', 3),('h',10),('h', 5),('h', 1),('h', 3),('h', 5),('h',10),\n",
    "               ('h',10),('h',10),('h',10),('h',11),('h',11),('h',12),('h',13),('h',13),('h',14),('h',14),\n",
    "               ('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),('l', 3),\n",
    "               ('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),('h', 5),\n",
    "               ('h', 3),('h', 3),('h', 3),('h', 3),('h', 3),('h', 3),('h', 3),('h', 3),('h', 3),('h', 3)] * 10\n",
    "\n",
    "train_types = public_types * 500\n",
    "\n",
    "try:\n",
    "    train_s = torch.load(\"train_s\")\n",
    "    assert train_s.shape==(2,len(train_types),SEGMENT_SIZE,1)\n",
    "except:\n",
    "    train_s = np.nan * torch.empty(2,len(train_types),SEGMENT_SIZE,1)\n",
    "    for i,segment in progress_bar(enumerate(train_types),total=len(train_types)):\n",
    "        train_s[0,i],train_s[-1,i] = get_synth_segment_xy(*segment)\n",
    "    torch.save(train_s,\"train_s\")\n",
    "\n",
    "#np.bincount(train_s[2,...].flatten(),minlength=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def filter(x):\n",
    "    return mne.filter.notch_filter(x.numpy().astype('float64'),10000,50.0)\n",
    "train[0,:]=Tensor(filter(train[0,:]))\n",
    "test[0,:] =Tensor(filter( test[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,train_s.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train   =   train.view(  train.shape[0],-1,SEGMENT_SIZE,1)\n",
    "test    =    test.view(   test.shape[0],-1,TEST_SEGMENT_SIZE,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[:,[0,1,2,3,4,5,6,8,9],...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_mean, signal_std = train[0].mean(),train[0].std()\n",
    "signal_min = (min(train[0].min(), test[0].min())-0.4-signal_mean)/signal_std\n",
    "signal_max = (max(train[0].max(), test[0].max())+0.4-signal_mean)/signal_std\n",
    "signal_min, signal_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0\n",
    "split_size = SEGMENT_SIZE//WINDOW_SIZE//SPLITS\n",
    "windows_per_segment = np.arange(SEGMENT_SIZE//WINDOW_SIZE)\n",
    "valid_split_idx = split*split_size + np.arange(split_size)\n",
    "all_segments = range(train.shape[1])\n",
    "valid_idx = list(product(range(50) if XTRA_DS else all_segments,valid_split_idx))\n",
    "train_idx = list(product(all_segments,windows_per_segment))\n",
    "train_idx = list(sorted(set(train_idx).difference(set(valid_idx))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_per_segment,split_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data,idx=None,jitter=False,shift=0):\n",
    "        super().__init__()\n",
    "        self.data, self.jitter,self.shift = data, jitter, shift\n",
    "        self.segment_size = data.shape[-2]\n",
    "        self.idx = ifnone(idx,list(product(range(self.data.shape[1]),np.arange(self.segment_size//WINDOW_SIZE))))\n",
    "        self.n_inp = 1\n",
    "        self.has_y = self.data.shape[0] == 2\n",
    "        self.idx_set = set(self.idx)\n",
    "        self.histc = {}\n",
    "        for s in range(self.data[0].shape[0]):\n",
    "            x = self.data[0,s].cuda()\n",
    "            #x_max, x_min = x.max(),x.min()\n",
    "            histc = torch.histc(x,bins=HIST_BINS,min=signal_min,max=signal_max)\n",
    "            histc /= histc.max()\n",
    "            #histc = torch.empty((HIST_BINS,))\n",
    "            #histc[2:] = torch.histc(x,bins=HIST_BINS-2,min=x_min,max=x_max)\n",
    "            #histc /= histc[2:].max()\n",
    "            #histc[0],histc[1] =  x_max, x_min\n",
    "            self.histc[s] = histc.cpu()\n",
    "            del x\n",
    "    def __len__(self): return len(self.idx)\n",
    "    def __getitem__(self, idx):\n",
    "        s,o=self.idx[idx]\n",
    "        jitter = 0\n",
    "        if self.jitter:\n",
    "            os,oe = 0,0\n",
    "            if ((s,(o-1)) in self.idx_set): os = -WINDOW_SIZE//2\n",
    "            if ((s,(o+1)) in self.idx_set): oe =  WINDOW_SIZE//2\n",
    "            jitter = torch.randint(os,oe,(1,)).item()\n",
    "        so,se = jitter+o*WINDOW_SIZE,jitter+(o+1)*WINDOW_SIZE\n",
    "        assert (so < self.segment_size) and (se <= self.segment_size)\n",
    "        so,se = so + self.shift, se + self.shift\n",
    "        ss = (torch.arange(so,se) % self.segment_size) if (se > self.segment_size) else slice(so,se)\n",
    "        x =  (self.data[0,s,ss,:], self.histc[s])\n",
    "        if self.has_y: y_open_channels = self.data[-1,s:s+1,ss,0].long()\n",
    "        return (x,y_open_channels) if self.has_y else (x,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train_ds = IonDataset((train, train_channels_in_segment), train_idx, jitter=False, synth=True)\n",
    "len(train_ds)\n",
    "x = torch.empty((len(train_ds),train_ds[0][0].shape[0]))\n",
    "print(x.shape)\n",
    "for i in range(len(train_ds)): x[i] = train_ds[i][0].squeeze()\n",
    "plt.plot(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_ds   = IonDataset(train_s,   jitter=True)\n",
    "public_s_ds  = IonDataset(public_s)\n",
    "private_s_ds = IonDataset(private_s)\n",
    "train_ds     = IonDataset(train)\n",
    "test_ds      = IonDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(Transform):\n",
    "    parameters,order=L('mean', 'std'),99\n",
    "    def __init__(self,mean,std): self.mean,self.std =mean,std\n",
    "    def encodes(self,xy): return [((t[0]-self.mean) / self.std,t[1]) if i==0 else t for i,t in enumerate(xy)]\n",
    "\n",
    "def make_ds(ds,shuffle=False,after_batch= Normalize(signal_mean,signal_std)):\n",
    "           return DataLoader(ds, BS, shuffle=shuffle, num_workers=32, pin_memory=True, \n",
    "                             after_batch= after_batch)\n",
    "            \n",
    "train_s_dl   = make_ds(train_s_ds,True)\n",
    "public_s_dl  = make_ds(public_s_ds)\n",
    "private_s_dl = make_ds(private_s_ds)\n",
    "train_dl     = make_ds(train_ds)\n",
    "test_dl      = make_ds(test_ds)\n",
    "\n",
    "dls = DataLoaders(train_s_dl, public_s_dl, test_dl, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = (train[0] - signal_mean) / signal_std\n",
    "for b in range(tn.shape[0]):\n",
    "    print(tn[b].min(), tn[b].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(iter(test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.models.qrnn import QRNN\n",
    "class oldClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        f_out = 32\n",
    "\n",
    "        self.RNN0 = QRNN(input_size=FEAT_WINDOW, hidden_size=f_out, n_layers=1, batch_first=True, \n",
    "                            bidirectional=True, dropout=0.)\n",
    "        self.RNN1  = QRNN(input_size=f_out*2, hidden_size=f_out, n_layers=2, batch_first=True, \n",
    "                            bidirectional=True, dropout=0.)\n",
    "        self.fc = nn.Sequential(nn.Linear(HIST_BINS+f_out*2, f_out),    Swish(),\n",
    "                              nn.Linear(f_out,   f_out//2), Swish(),\n",
    "                              nn.Linear(f_out//2,11))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x,hist = x\n",
    "        hist = hist.unsqueeze(1).expand(-1,x.shape[1],-1)\n",
    "        n_pad = 64\n",
    "        x = nn.ReflectionPad1d(n_pad)(x.permute(0,2,1)).permute(0,2,1)\n",
    "        x, _ = self.RNN0(x)\n",
    "        x, _ = self.RNN1(x)\n",
    "        x = x[:,n_pad:-n_pad,:]\n",
    "        return self.fc(torch.cat((x,hist),dim=-1)),x\n",
    "\n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        f = 256\n",
    "        k = 5\n",
    "        p = (k-1)//2\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1,f,k,padding=p,padding_mode='replicate'), Swish(),\n",
    "            nn.Conv1d(f,f,k,padding=p,padding_mode='replicate'), Swish(),\n",
    "            nn.Conv1d(f,f,k,padding=p,padding_mode='replicate'), Swish(),\n",
    "            nn.Conv1d(f,f,k,padding=p,padding_mode='replicate'), Swish(),\n",
    "            nn.Conv1d(f,f,k,padding=p,padding_mode='replicate'), Swish(),\n",
    "            nn.Conv1d(f,f,k,padding=p,padding_mode='replicate'), Swish())\n",
    "        \n",
    "        self.hist = nn.Sequential(\n",
    "            nn.Linear(HIST_BINS   , HIST_BINS*4), Swish(),\n",
    "            nn.Linear(HIST_BINS*4 , HIST_BINS*4), Swish(),\n",
    "            nn.Linear(HIST_BINS*4 , f)          , Swish(),            \n",
    "        )\n",
    "        \n",
    "        self.lin  = nn.Sequential(\n",
    "            nn.Conv1d(2*f ,2*f ,1), Swish(),\n",
    "            nn.Conv1d(2*f ,2*f, 1) ,Swish(),\n",
    "            nn.Conv1d(2*f ,11  ,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, hist = x \n",
    "        hist = self.hist(hist) # B HIST_BINS -> B f_hist\n",
    "        hist = hist.unsqueeze(-1).expand(-1,-1,x.shape[1]) # -> B f_hist WINDOW_SIZE\n",
    "        x  = x.view(x.shape[0],1,-1) # B 1 WINDOW_SIZE \n",
    "        x = self.conv(x) # -> B f WINDOW_SIZE\n",
    "        x = torch.cat((x,hist),dim=1) # -> B (f+f_hist) WINDOW_SIZE\n",
    "        return self.lin(x).permute(0,2,1),x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = ReformerLM(\n",
    "    num_tokens = 11,\n",
    "    dim = dim,\n",
    "    depth = depth,\n",
    "    max_seq_len = WINDOW_SIZE,\n",
    "    heads = heads,\n",
    "    lsh_dropout = lsh_dropout,\n",
    "    bucket_size=bucket_size,\n",
    "    causal = False,\n",
    "    use_full_attn = False,\n",
    "    fixed_position_emb = False,\n",
    "    n_hashes = 4,\n",
    ")\n",
    "model.token_emb = nn.Linear(1,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softf1_loss(logits,true,weights=None,label_smoothing=0.):\n",
    "    # 96 4000 11, 96 4000 1 \n",
    "    n_classes = logits.shape[-1]\n",
    "    weights = ifnone(weights,torch.ones((n_classes,),dtype=logits.dtype,device=logits.device))\n",
    "    y_pred = logits.view(-1,n_classes).softmax(dim=-1)             \n",
    "    y_true = F.one_hot(true.flatten(), n_classes).float()\n",
    "    if label_smoothing > 0: y_true = y_true *(1-label_smoothing) + label_smoothing/n_classes\n",
    "\n",
    "    tp = (y_true * y_pred).sum(dim=0).float()\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).float()\n",
    "    fp = ((1 - y_true) * y_pred).sum(dim=0).float()\n",
    "    fn = (y_true * (1 - y_pred)).sum(dim=0).float()\n",
    "\n",
    "    precision = tp / (tp + fp )\n",
    "    recall    = tp / (tp + fn )\n",
    "\n",
    "    f1 = 2* (precision*recall) / (precision + recall )\n",
    "    #f1 = f1.clamp(0,1) * weights\n",
    "    f1 = f1[~torch.isnan(f1)].mean()\n",
    "    return 1-f1\n",
    "\n",
    "class SoftF1Loss(Module):\n",
    "    def __init__(self, label_smoothing=0,weight=None): self.weight,self.label_smoothing = weight,label_smoothing\n",
    "    def forward(self, output, target): return softf1_loss(output, target, self.weight,self.label_smoothing)\n",
    "\n",
    "class SmartLabelSmoothingCE(Module):\n",
    "    def __init__(self, label_smoothing:float=0.0): \n",
    "        self.label_smoothing = Tensor([\n",
    "            [0,1,0,0,0,0,0,0,0,0,0],\n",
    "            [1,0,1,0,0,0,0,0,0,0,0],\n",
    "            [0,1,0,1,0,0,0,0,0,0,0],\n",
    "            [0,0,1,0,1,0,0,0,0,0,0],\n",
    "            [0,0,0,1,0,1,0,0,0,0,0],\n",
    "            [0,0,0,0,1,0,1,0,0,0,0],\n",
    "            [0,0,0,0,0,1,0,1,0,0,0],\n",
    "            [0,0,0,0,0,0,1,0,1,0,0],\n",
    "            [0,0,0,0,0,0,0,1,0,1,0],\n",
    "            [0,0,0,0,0,0,0,0,1,0,1],\n",
    "            [0,0,0,0,0,0,0,0,0,1,0],\n",
    "        ])\n",
    "        self.label_smoothing  *= (label_smoothing / self.label_smoothing.sum(dim=1,keepdims=True))\n",
    "        self.label_smoothing += (1-label_smoothing) * torch.eye(11)\n",
    "        \n",
    "    def forward(self, logits, true):\n",
    "        n_classes = logits.size()[-1]\n",
    "        y_pred = logits.view(-1,n_classes)    \n",
    "        y_true = self.label_smoothing[true.flatten()].view(-1,n_classes).to(logits.device)\n",
    "        return (- y_true * F.log_softmax(y_pred, dim=1)).sum(dim=1).mean()\n",
    "\n",
    "class LabelSmoothingCE(Module):\n",
    "    def __init__(self, eps:float=0.65, reduction='mean'): self.eps,self.reduction = eps,reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        output = output.permute(0,2,1) # => B C S\n",
    "        target = target.squeeze(1)     # => B S\n",
    "        log_preds = F.log_softmax(output, dim=1)\n",
    "        if self.reduction=='sum': loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=1)\n",
    "            if self.reduction=='mean':  loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "\n",
    "class DriftChannelsLoss(Module):\n",
    "    def __init__(self, losses, weights=None):\n",
    "        self.losses, self.weights = losses, ifnone(weights, [1.] * len(losses))\n",
    "    def __call__(self, input:Tensor, target:Tensor, **kwargs):\n",
    "        i_open_channels, _ = input\n",
    "        t_open_channels    = target\n",
    "        loss = L([l(i_open_channels,t_open_channels)*w for l,w in zip(self.losses, self.weights)]).sum()\n",
    "        return loss\n",
    "    \n",
    "sls = SmartLabelSmoothingCE(0.1)\n",
    "sls(Tensor([[[0,0,0,0,0,0,0,0,0,0,10]]]),LongTensor([[[10]]]))\n",
    "SoftF1Loss()(Tensor([[[0,0,0,0,0,0,0,0,0,0,10]]]),LongTensor([[[10]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "# Cell\n",
    "class OpenChannelsAccumMetric(Metric):\n",
    "    \"Stores predictions and targets on CPU in accumulate to perform final calculations with `func`.\"\n",
    "    def __init__(self, func, dim_argmax=None, sigmoid=False, thresh=None, to_np=False, invert_arg=False,\n",
    "                 flatten=True, metric_name=None, **kwargs):\n",
    "        store_attr(self,'func,dim_argmax,sigmoid,thresh,flatten,metric_name')\n",
    "        self.to_np,self.invert_args,self.kwargs = to_np,invert_arg,kwargs\n",
    "\n",
    "    def reset(self): self.targs,self.preds = [],[]\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        t,p = learn.y,learn.pred[0] #learn.y[1],learn.pred[1]\n",
    "        pred = p.argmax(dim=self.dim_argmax) if self.dim_argmax else p\n",
    "        if self.sigmoid: pred = torch.sigmoid(pred)\n",
    "        if self.thresh:  pred = (pred >= self.thresh)\n",
    "        #pred = p.round()\n",
    "        targ = t\n",
    "        pred,targ = to_detach(pred),to_detach(targ)\n",
    "        if self.flatten: pred,targ = flatten_check(pred,targ)\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(targ)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.preds) == 0: return\n",
    "        preds,targs = torch.cat(self.preds),torch.cat(self.targs)\n",
    "        if self.to_np: preds,targs = preds.numpy(),targs.numpy()\n",
    "        return self.func(targs, preds, **self.kwargs) if self.invert_args else self.func(preds, targs, **self.kwargs)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return ifnone(self.metric_name,self.func.func.__name__ if hasattr(self.func, 'func') else  self.func.__name__)\n",
    "\n",
    "# Cell\n",
    "def skm_to__open_channels_fastai(func, is_class=True, thresh=None, axis=-1, sigmoid=None, **kwargs):\n",
    "    \"Convert `func` from sklearn.metrics to a fastai metric\"\n",
    "    dim_argmax = axis if is_class and thresh is None else None\n",
    "    sigmoid = sigmoid if sigmoid is not None else (is_class and thresh is not None)\n",
    "    return OpenChannelsAccumMetric(func, dim_argmax=dim_argmax, sigmoid=sigmoid, thresh=thresh,\n",
    "                       to_np=True, invert_arg=True, **kwargs)\n",
    "\n",
    "def MF1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None, **kwargs):\n",
    "    \"F1 score for single-label classification problems\"\n",
    "    return skm_to__open_channels_fastai(skm.f1_score, axis=axis,\n",
    "                         labels=labels, pos_label=pos_label, average=average, sample_weight=sample_weight, **kwargs)\n",
    "\n",
    "def A(inp, targ, axis=-1):\n",
    "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
    "    pred,targ = inp[0],targ#inp[1], targ[1]\n",
    "    pred,targ = flatten_check(pred.argmax(dim=axis), targ)\n",
    "    return (pred == targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets = [MF1Score(labels=[l],average='macro', metric_name=f\"f1_{l}\") for l in range(11)]\n",
    "mets.extend([MF1Score(labels=list(range(11)),average='macro', metric_name=f\"f1\"), A])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "learn = Learner(dls,model,loss_func=DriftChannelsLoss([CrossEntropyLossFlat()]),metrics=mets, moms=None,)\n",
    "\n",
    "#learn.callbacks.extend([F1Metric(learn)])\n",
    "\n",
    "learn.to_parallel().to_fp16()\n",
    "summary = learn.summary()\n",
    "match = re.search(r'Total trainable params: ([0-9,]+)', summary)\n",
    "model_params = int(match.group(1).replace(\",\",\"\"))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'lstm6843915_t62500_v11250_BS384_SS500000_WS400_FW1_cv0.9424_clean_synth'\n",
    "try:\n",
    "    learn.load(modelname, strict=True)\n",
    "    print(f\"Loaded {modelname}\")\n",
    "except:\n",
    "    print(f\"Failed to load {modelname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_min, lr_steep=learn.lr_find(end_lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func=DriftChannelsLoss([CrossEntropyLossFlat()],[1.])\n",
    "learn.fit_one_cycle(1,lr_max=1e-2,moms=(0.95, 0.85, 0.95),pct_start=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func=DriftChannelsLoss([ SoftF1Loss()])\n",
    "learn.fit_flat_cos(1,lr=1e-3,pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func=DriftChannelsLoss([ SoftF1Loss()])\n",
    "learn.fit_flat_cos(1,lr=1e-4,pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func=DriftChannelsLoss([SoftF1Loss(label_smoothing=0.),LabelSmoothingCE()],[40.,1])\n",
    "learn.fit_flat_cos(1,1e-2,pct_start=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_flat_cos(1,5e-4,pct_start=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func=DriftChannelsLoss([LabelSmoothingCE(0.75)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_flat_cos(20,1e-3,pct_start=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_s_dl.device=default_device()\n",
    "p = learn.get_preds(dl=public_s_dl)\n",
    "y_pred = p[0][0].argmax(dim=-1).flatten()\n",
    "y_true = p[1].flatten()\n",
    "public_cv=skm.f1_score(y_true,y_pred,labels=range(11),average='macro')\n",
    "public_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_s_dl.device=default_device()\n",
    "p = learn.get_preds(dl=private_s_dl)\n",
    "y_pred = p[0][0].argmax(dim=-1).flatten()\n",
    "y_true = p[1].flatten()\n",
    "private_cv=skm.f1_score(y_true,y_pred,labels=range(11),average='macro')\n",
    "private_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl.device=default_device()\n",
    "p = learn.get_preds(dl=train_dl)\n",
    "y_pred = p[0][0].argmax(dim=-1).flatten()\n",
    "y_true = p[1].flatten()\n",
    "train_cv=skm.f1_score(y_true,y_pred,labels=range(11),average='macro')\n",
    "train_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv,_,time = learn.recorder.log[-3:];cv,_,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix =  '_synth_clean50hz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = f'conv_bn_swift_{model_params}_t{len(train_s_ds)}_v{len(public_s_ds)}_BS{BS}_SS{SEGMENT_SIZE}_WS{WINDOW_SIZE}_pucv{public_cv:0.06f}_prcv{private_cv:0.06f}_trcv{train_cv:0.06f}{DATA_SUFFIX}{suffix}'\n",
    "learn.save(modelname);modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds, valid_preds = learn.get_preds(0), learn.get_preds(1)\n",
    "train_preds = train_preds[0][1],train_preds[1]\n",
    "valid_preds = valid_preds[0][1],valid_preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_feats = train_preds[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack((learn.model.fc._parameters['weight'].t().cpu().detach().numpy().flatten(),\n",
    "                learn.model.fc._parameters['bias'].cpu().detach().numpy().flatten()))\n",
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y = train_preds[0].view(-1,d_feats).cuda(),train_preds[1].view(-1).cuda()\n",
    "x = y = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "#x,y = valid_preds[0].view(-1,d_feats).cuda(),valid_preds[1].view(-1).cuda()\n",
    "x,y = train_preds[0].view(-1,d_feats).cuda(),train_preds[1].view(-1).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true   = y\n",
    "evals = 0\n",
    "max_evals = len(x0) \n",
    "print(max_evals)\n",
    "imb = master_bar(range(max_evals), total=max_evals)\n",
    "def adjust_thresholds(thresholds):\n",
    "    global evals,imb\n",
    "    m = Tensor(thresholds[:11*d_feats]).view(d_feats,11).cuda()\n",
    "    b = Tensor(thresholds[11*d_feats:]).view(1,11).cuda()\n",
    "    preds = (x @ m + b).argmax(dim=-1)\n",
    "    \n",
    "    y_pred = F.one_hot(preds,11)                    # S, C\n",
    "    y_true = F.one_hot(true, 11).to(torch.float32)  # S, C\n",
    "    \n",
    "    tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "    precision = tp / (tp + fp )\n",
    "    recall = tp / (tp + fn )\n",
    "\n",
    "    f1 = 2* (precision*recall) / (precision + recall)\n",
    "    f1 = f1.mean().cpu().numpy()\n",
    "\n",
    "    if evals % 1000 == 0: print(f'{100*evals/max_evals:0.02f}% {f1:0.06f}')#, thresholds)\n",
    "    evals += 1\n",
    "    return 1-f1\n",
    "    \n",
    "def callback(xk):\n",
    "    print(evals)\n",
    "    return False if evals > max_evals else True\n",
    "\n",
    "res = scipy.optimize.minimize(adjust_thresholds, x0,method='Powell', \n",
    "                              options={'disp':True, 'maxfev' : max_evals },\n",
    "                              callback= callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.fc._parameters['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.fc._parameters['weight'].data = Tensor(res.x[:11*d_feats]).view(d_feats,11).t().cuda()\n",
    "learn.model.fc._parameters['bias'].data   = Tensor(res.x[11*d_feats:]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.fc._parameters['weight'],learn.model.fc._parameters['bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.d = data[0].shape[-1]\n",
    "        self.x,self.y = data[0].view(-1,self.d),data[1].view(-1)\n",
    "        self.n_inp = 1\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx): return self.x[idx].unsqueeze(1),self.y[idx]#.unsqueeze(-1)\n",
    "    \n",
    "f1_train_ds,f1_valid_ds = F1Dataset(train_preds), F1Dataset(valid_preds)\n",
    "f1_train_dl = DataLoader(f1_train_ds, len(f1_train_ds)//100, shuffle=True,   num_workers=8, pin_memory=True)\n",
    "f1_valid_dl = DataLoader(f1_valid_ds, len(f1_train_ds)//100, shuffle=False,  num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_feats = train_preds[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1model = nn.Sequential(nn.Conv1d(d_feats   , d_feats//2,3,1,1,groups=1), nn.ReLU(), \n",
    "                        nn.Conv1d(d_feats//2, d_feats//4,3,1,1,groups=1), nn.ReLU(), \n",
    "                        nn.Conv1d(d_feats//4 ,        11,3,1,1,groups=1),\n",
    "                        Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1learn = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1learn = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "f1learn = Learner(DataLoaders(f1_train_dl,f1_valid_dl, device=default_device()),f1model,\n",
    "                  loss_func=CrossEntropyLossFlat(),opt_func=Adam,\n",
    "                  metrics=[F1Score(labels=list(range(11)),average='macro'), accuracy])\n",
    "f1learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1learn.fit(1,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1learn.loss_func = softf1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1learn.fit_one_cycle(20,5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model=learn.model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl.dataset.data[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift 1 sample to the right!!! (we need to reverse it later!)\n",
    "dd = test.flatten().clone() # torch.empty_like(test_dl.dataset.data.flatten())\n",
    "dd[1:] = test_dl.dataset.data.flatten()[:-1]\n",
    "dd[0]  = test_dl.dataset.data.flatten()[-1]\n",
    "test_dl.dataset.data =  dd.view(test_dl.dataset.data.shape)\n",
    "test_dl.dataset.data[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_dl.dataset.data[0,0,:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.model = learn.model.module.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "test_preds  = torch.zeros(*test[0].squeeze().shape,11,dtype=torch.float)\n",
    "test_preds_ = torch.empty_like(test_preds)\n",
    "n_tta = 0\n",
    "learn.model = nn.DataParallel(learn.model)\n",
    "with torch.no_grad():\n",
    "    mb = master_bar(np.linspace(0,WINDOW_SIZE,endpoint=False,num=5,dtype=np.int))\n",
    "    for shift in mb:\n",
    "        test_dl.dataset.shift = shift\n",
    "        test_preds_ = test_preds_.view(-1,11)\n",
    "        test_preds_[...] = 0.\n",
    "        s = 0\n",
    "        for xx in progress_bar(test_dl,parent=mb):\n",
    "            x = xx[0]\n",
    "            preds = learn.model((x[0].cuda(),x[1].cuda()))\n",
    "            open_channels,_ = preds\n",
    "            open_channels = open_channels.view(-1,11)\n",
    "            l = open_channels.shape[0]\n",
    "            test_preds_[s:s+l] += open_channels.cpu()\n",
    "            s += l\n",
    "        test_preds_ = test_preds_.view(-1,TEST_SEGMENT_SIZE,11)\n",
    "        ss = torch.arange(0+shift,TEST_SEGMENT_SIZE+shift) % TEST_SEGMENT_SIZE\n",
    "        for segment in range(test_preds_.shape[0]):\n",
    "            test_preds[segment,ss] += test_preds_[segment,...]\n",
    "        n_tta +=1\n",
    "learn.model = learn.model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds.view(-1,11)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_channels = test_preds.argmax(dim=1)\n",
    "open_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test[0,:].flatten())\n",
    "plt.plot(open_channels+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_types = [('l',1),('l',2),('l',3),('l',4),('l',5),\n",
    "           ('h',1),('h',2),('h',3),('h',4),('h',5),('h',10)]\n",
    "p_dist = np.zeros((len(m_types),11))\n",
    "for _ in range(100):\n",
    "    for i,m_type in enumerate(m_types):\n",
    "        p_dist[i] += np.bincount(get_synth_segment_y(*m_type,SEGMENT_SIZE),minlength=11)/(SEGMENT_SIZE)\n",
    "p_dist /= 100\n",
    "ts_densities = np.array(\n",
    "    [np.bincount(open_channels.view(-1,TEST_SEGMENT_SIZE)[b],minlength=11)/TEST_SEGMENT_SIZE for b in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_types = [('l',1),('l',2),('l',3),('l',4),('l',5),\n",
    "           ('h',1),('h',2),('h',3),('h',4),('h',5),('h',10)]\n",
    "p_dist = np.zeros((len(m_types),11))\n",
    "for _ in range(100):\n",
    "    for i,m_type in enumerate(m_types):\n",
    "        p_dist[i] += np.bincount(get_synth_segment_y(*m_type,SEGMENT_SIZE),minlength=11)/(SEGMENT_SIZE)\n",
    "p_dist /= 100\n",
    "ts_densities = np.array(\n",
    "    [np.bincount(train[-1,b].squeeze(),minlength=11)/SEGMENT_SIZE for b in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "t_types = []\n",
    "for d in distance.cdist(ts_densities,p_dist): t_types.append(m_types[d.argmin()])\n",
    "t_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0,...,0].flatten().shape,open_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(100_000, -5, 10, label='pyplot vertical line')\n",
    "plt.plot(test[0,...,0].flatten()[:2000000//3])\n",
    "plt.plot(open_channels[:2000000//3]+8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test[0,...,0].flatten()[2000000//3:])\n",
    "plt.plot(open_channels[2000000//3:]+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_types = [('l', 1),\n",
    " ('l', 1),\n",
    " ('h', 1),\n",
    " ('h', 3),\n",
    " ('h', 10),\n",
    " ('h', 5),\n",
    " ('h', 1),\n",
    " ('h', 5),\n",
    " ('h', 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_types_std = defaultdict(list)\n",
    "for s,tt in enumerate(train_types):\n",
    "    xs = train[ 0,s,:].flatten()\n",
    "    ys = train[-1,s,:].flatten()\n",
    "    print(ys.shape,xs.shape)\n",
    "    x_pred = get_synth_segment_xy(None,None,size=SEGMENT_SIZE,y=ys,add_noise=False)[0].flatten()\n",
    "    plt.plot(xs-x_pred)\n",
    "    std = (xs-x_pred).std().item()\n",
    "    train_types_std[tt].append(std)\n",
    "    #plt.plot(x_pred)\n",
    "\n",
    "    train_types_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types_std = defaultdict(list)\n",
    "st,sl=5000,10000\n",
    "for s in [1]:\n",
    "    xs = test_dl.dataset.data[0,s,:]\n",
    "    ys = open_channels.view(-1,TEST_SEGMENT_SIZE)[s]\n",
    "    x_pred = get_synth_segment_xy(None,None,size=TEST_SEGMENT_SIZE,y=ys,add_noise=False)[0]\n",
    "    residual = xs-x_pred\n",
    "    l = slice(st,st+sl)\n",
    "    plt.plot(xs[l])\n",
    "    plt.plot(x_pred[l]-2)\n",
    "    plt.plot(residual[l])\n",
    "    std = (residual).std().item()\n",
    "    print(std)\n",
    "    test_types_std[tt].append((xs-x_pred).std())\n",
    "    #plt.plot(x_pred)\n",
    "residual.abs().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_types_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fname = f'{modelname}_n_tta{n_tta}.csv';csv_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = test.flatten().clone() # torch.empty_like(test_dl.dataset.data.flatten())\n",
    "dd[1:] = test_dl.dataset.data.flatten()[:-1]\n",
    "dd[0]  = test_dl.dataset.data.flatten()[-1]\n",
    "test_dl.dataset.data =  dd.view(test_dl.dataset.data.shape)\n",
    "test_dl.dataset.data[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_channels_shifted = open_channels.clone()\n",
    "open_channels_shifted[:-1] = open_channels[1:]\n",
    "open_channels_shifted[-1]  = open_channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(open_channels_shifted[:TEST_SEGMENT_SIZE])\n",
    "plt.plot(test.flatten()[:TEST_SEGMENT_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = p_input / 'sample_submission.csv'\n",
    "ss = pd.read_csv(submission_csv_path, dtype={'time': str})\n",
    "test_preds_all = test_preds\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str), 'open_channels': open_channels_shifted})\n",
    "test_pred_frame.to_csv(csv_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c 'liverpool-ion-switching' -f {csv_fname} -m 'PU {public_cv} PR {private_cv} TR {train_cv}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
