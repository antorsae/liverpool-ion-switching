{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.distributed import *\n",
    "from fastai2.data.transforms import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reformer_pytorch import Reformer, ReformerLM\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import random\n",
    "#from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations and main hyperparammeters\n",
    "SEGMENT_SIZE = 100000 # 500000\n",
    "WINDOW_SIZE = 200\n",
    "BS = 3*38\n",
    "SPLITS = 5\n",
    "\n",
    "assert SEGMENT_SIZE % WINDOW_SIZE == 0\n",
    "assert (SEGMENT_SIZE // WINDOW_SIZE) % SPLITS == 0\n",
    "SEED = 321\n",
    "DATA_SUFFIX = '_clean'\n",
    "\n",
    "p_input = Path('input')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_dtypes = {'time': np.float32, 'signal': np.float32, 'open_channels': np.int32 }\n",
    "test_dtypes  = {'time': np.float32, 'signal': np.float32 }\n",
    "df_train  = pd.read_csv(p_input / f'train.csv', dtype= train_dtypes)\n",
    "df_test   = pd.read_csv(p_input / f'test.csv',  dtype= test_dtypes)\n",
    "df_train_drift = pd.read_csv(p_input / f'train{DATA_SUFFIX}.csv', dtype= train_dtypes)\n",
    "df_test_drift  = pd.read_csv(p_input / f'test{DATA_SUFFIX}.csv',  dtype= test_dtypes)\n",
    "sub   = pd.read_csv(p_input / 'sample_submission.csv',  dtype={'time': np.float32})\n",
    "df_train['drift'] = df_train['signal'] - df_train_drift['signal']\n",
    "df_test['drift']  = df_test['signal']  - df_test_drift['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['signal'] =  df_train_drift['signal']\n",
    "df_test['signal']  =   df_test_drift['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train),SEGMENT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['open_channels'][2300000:2400000][(df_train['open_channels'][2300000:2400000]==0)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_xtra_csvs = {\n",
    "    1: ['outfinaltest10.csv',  'outfinaltest44.csv',],#  'outfinaltest78.csv',],  'outfinaltest10.csv',  'outfinaltest44.csv'],\n",
    "    3: ['outfinaltest1.csv',   'outfinaltest2.csv',   'outfinaltest3.csv',   'outfinaltest4.csv', 'outfinaltest5.csv'],\n",
    "    5: ['outfinaltest328.csv', 'outfinaltest534.csv', 'outfinaltest747.csv',]#, 'outfinaltest328.csv', 'outfinaltest534.csv']\n",
    "}\n",
    "\n",
    "df_train_xtra = None\n",
    "for _,xtra_csvs in d_xtra_csvs.items():\n",
    "    print(_,xtra_csvs)\n",
    "    for xtra_csv in xtra_csvs:\n",
    "        xx = pd.read_csv(p_input / xtra_csv , header=None,names=['time', 'signal', 'open_channels'])\n",
    "        df_train_xtra = pd.concat((xx,df_train_xtra), axis=0)\n",
    "df_train_xtra['drift']  = 0.\n",
    "df_train = pd.concat((df_train,df_train_xtra), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channels_in_segment=[]\n",
    "for s in range(0,len(df_train),SEGMENT_SIZE):\n",
    "    channels = LongTensor(df_train['open_channels'][s:s+SEGMENT_SIZE].unique())\n",
    "    channels_hot = torch.zeros(11,11)\n",
    "    channels_hot = channels_hot.scatter(0,channels.unsqueeze(0), 1.).sum(dim=1)\n",
    "    train_channels_in_segment.append(channels_hot)\n",
    "train_channels_in_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_channels_in_segment = FloatTensor([\n",
    "    [1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,1,1,0,0,0,0,0,0,0],\n",
    "    [0,0,1,1,1,1,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,1,1,1,1,1], # \n",
    "    [0,1,1,1,1,1,0,0,0,0,0],\n",
    "    [0,0,0,0,0,1,1,1,1,1,1],\n",
    "    [1,1,0,0,0,0,0,0,0,0,0],\n",
    "    [0,1,1,1,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0], # \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.cat((torch.FloatTensor(df_train['signal'        ].values).unsqueeze(0),\n",
    "                   torch.FloatTensor(df_train['drift'         ].values).unsqueeze(0),\n",
    "                   torch.FloatTensor(df_train['open_channels' ].values).unsqueeze(0)))\n",
    "test  = torch.cat((torch.FloatTensor(df_test ['signal'        ].values).unsqueeze(0),\n",
    "                   torch.FloatTensor(df_test ['drift'         ].values).unsqueeze(0)))\n",
    "signal = torch.cat((train[0],test[0]))\n",
    "signal_mean, signal_std = signal.mean(),signal.std()\n",
    "train[0] = (train[0] - signal_mean) / signal_std\n",
    "test[0]  = ( test[0] - signal_mean) / signal_std\n",
    "train = train.view(train.shape[0],-1,SEGMENT_SIZE)\n",
    "test  =  test.view( test.shape[0], -1,SEGMENT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5\n",
    "rcParams['figure.dpi'] = 300\n",
    "rcParams['agg.path.chunksize'] = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[0,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train[1,:].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0\n",
    "split_size = SEGMENT_SIZE//WINDOW_SIZE//SPLITS\n",
    "valid_idx = split*split_size + np.arange(split_size)\n",
    "train_idx = np.setdiff1d(np.arange(SEGMENT_SIZE//WINDOW_SIZE), valid_idx)\n",
    "train_idx, valid_idx = list(product(range(train.shape[1]),train_idx)), list(product(range(train.shape[1]),valid_idx))\n",
    "train_idx[:10],train_idx[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_idx = np.arange(SEGMENT_SIZE//WINDOW_SIZE)\n",
    "#valid_idx = train_idx\n",
    "#train_idx, valid_idx = list(product(range(train.shape[1]),train_idx)), list(product(range(train.shape[1]),valid_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s,o=train_idx[400*9]\n",
    "plt.plot(train[2,s,o*WINDOW_SIZE:(o+1)*WINDOW_SIZE])\n",
    "s,o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(t):\n",
    "    print(\"Hey t\")\n",
    "class IonDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data,idx=None,jitter=False,p_flip=0.):\n",
    "        super().__init__()\n",
    "        idx = ifnone(idx,list(product(range(data.shape[1]),np.arange(SEGMENT_SIZE//WINDOW_SIZE))))\n",
    "        self.data,self.idx,self.jitter,self.p_flip = data, idx, jitter, p_flip\n",
    "        self.n_inp = 1\n",
    "        self.has_y = data.shape[0] == 3\n",
    "    def __len__(self): return len(self.idx)\n",
    "    def __getitem__(self, idx):\n",
    "        s,o=self.idx[idx]\n",
    "        jitter = 0\n",
    "        if self.jitter:\n",
    "            os,oe = 0,0\n",
    "            if (s,(o-1)) in self.idx: os = -WINDOW_SIZE//2\n",
    "            if (s,(o+1)) in self.idx: oe =  WINDOW_SIZE//2\n",
    "            jitter = torch.randint(os,oe,(1,)).item()\n",
    "        ss = slice(jitter+o*WINDOW_SIZE,jitter+(o+1)*WINDOW_SIZE)\n",
    "        x =  self.data[0,s:s+1,ss]\n",
    "        flip = (torch.rand(1) < self.p_flip).item()\n",
    "        if flip: x=torch.flip(x,dims=(1,))\n",
    "        x = (x,train_channels_in_segment[s])\n",
    "        if self.has_y: \n",
    "            y_drift,y_open_channels = (self.data[1,s:s+1,ss], self.data[2,s:s+1,ss].long())\n",
    "            if flip: y_drift,y_open_channels=(torch.flip(y_drift,dims=(1,)),torch.flip(y_open_channels,dims=(1,)))\n",
    "            return (x,(y_drift,y_open_channels))\n",
    "        return (x,)\n",
    "    \n",
    "train_ds, valid_ds, test_ds = IonDataset(train, train_idx, jitter=True, p_flip=0.5), IonDataset(train, valid_idx), IonDataset(test)\n",
    "train_dl = DataLoader(train_ds, BS, shuffle=True,  num_workers=8, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, BS, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  BS, shuffle=False, num_workers=8, pin_memory=True)\n",
    "train_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =train_ds[0][0][0].unsqueeze(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 256\n",
    "print(x.shape)\n",
    "r = math.ceil(w/WINDOW_SIZE) + 1\n",
    "x_lead  = x.repeat(1,1,r)[...,:WINDOW_SIZE+w-1]\n",
    "x_lag   = x.repeat(1,1,r).flip((2))[...,:WINDOW_SIZE+w-1]\n",
    "lead,lag=x_lead.unfold(2,w,1), x_lag.unfold(2,w,1).flip((2))\n",
    "x=torch.cat((lead,lag),dim=3).squeeze(1)#.permute(0,2,1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.flatten(),test.flatten().flip(dims=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_ds[5][0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_ds[5][0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl, valid_dl, test_dl, device=default_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim, _):\n",
    "        super().__init__()\n",
    "        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = torch.arange(x.shape[1], device=x.device).type(self.inv_freq.type())\n",
    "        sinusoid_inp = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        emb = torch.cat((sinusoid_inp.sin(), sinusoid_inp.cos()), dim=-1)\n",
    "        return emb[None, :, :]\n",
    "    \n",
    "class AbsolutePositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(max_seq_len, dim)\n",
    "        self.emb.weight.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t = torch.arange(x.shape[1], device=x.device)\n",
    "        return self.emb(t)\n",
    "    \n",
    "class DummyDecoder(Module):\n",
    "    def __init__(self,dropout:float=0):\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,tgt, memory, tgt_mask=None, memory_mask=None, \n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        return self.dropout(memory)\n",
    "\n",
    "    \n",
    "class DummyEncoder(Module):\n",
    "    def __init__(self,dropout:float=0):\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,src, mask=None, src_key_padding_mask=None):\n",
    "        return self.dropout(src)\n",
    "\n",
    "    \n",
    "class Classiformer(Module):\n",
    "    def __init__(self, dim, depth, heads, lsh_dropout, bucket_size):\n",
    "        self.dim = dim\n",
    "        \n",
    "        if False:\n",
    "            self.reformer = Reformer(\n",
    "                dim = dim,\n",
    "                depth = depth,\n",
    "                max_seq_len = WINDOW_SIZE,\n",
    "                heads = heads,\n",
    "                lsh_dropout = lsh_dropout,\n",
    "                bucket_size=bucket_size,\n",
    "                causal = False\n",
    "            )\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            num_encoder_layers=0,num_decoder_layers=depth,\n",
    "            nhead=heads,d_model=dim,dim_feedforward=dim*8,dropout=lsh_dropout, \n",
    "            custom_encoder=DummyEncoder(dropout=0.))\n",
    "        \n",
    "        self.pos_emb = FixedPositionalEmbedding(dim, WINDOW_SIZE)\n",
    "        self.input_to_dim  = nn.Linear(1, dim)\n",
    "        self.drift         = nn.Linear(dim, 1)\n",
    "        self.open_channels = nn.Linear(dim, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x,mask_channels = x\n",
    "        # B 1 S\n",
    "        w = self.dim//2\n",
    "        #print(x.shape)\n",
    "        r = math.ceil(w/WINDOW_SIZE) + 1\n",
    "        x_lead  = x.repeat(1,1,r)[...,:WINDOW_SIZE+w-1]\n",
    "        x_lag   = x.repeat(1,1,r).flip((2))[...,:WINDOW_SIZE+w-1]\n",
    "        lead,lag=x_lead.unfold(2,w,1), x_lag.unfold(2,w,1).flip((2))\n",
    "        x=torch.cat((lead,lag),dim=3).squeeze(1)#.permute(0,2,1)\n",
    "\n",
    "        #print(x.shape)\n",
    "        #x = self.input_to_dim(x.permute(0,2,1))\n",
    "        \n",
    "        # B S d\n",
    "        #x = x + self.pos_emb(x).type(x.type())\n",
    "        x = x.permute(1,0,2)\n",
    "        x = self.transformer(x,x) # S,N,E => T,N,E\n",
    "                                  # S is the source sequence length, \n",
    "                                  # T is the target sequence length, \n",
    "                                  # N is the batch size, \n",
    "                                  # E is the feature number\n",
    "        x = x.permute(1,0,2)\n",
    "        drift         = self.drift(x)\n",
    "        open_channels = self.open_channels(x) * mask_channels.unsqueeze(1)\n",
    "        return drift, open_channels\n",
    "    \n",
    "\n",
    "class AtomTorchTransformer(Module):\n",
    "    def __init__(self,n_layers,n_heads,d_model,d_inner,embed_p:float=0,\n",
    "                 encoder_dropout:float=0,decoder_dropout:float=0,\n",
    "                 d_head=None,deep_decoder=False,dense_out=False, **kwargs):\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        d_head = ifnone(d_head, d_model//n_heads)        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 512\n",
    "bucket_size = 50\n",
    "depth = 16\n",
    "heads = 16\n",
    "lsh_dropout = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = ReformerLM(\n",
    "    num_tokens = 11,\n",
    "    dim = dim,\n",
    "    depth = depth,\n",
    "    max_seq_len = WINDOW_SIZE,\n",
    "    heads = heads,\n",
    "    lsh_dropout = lsh_dropout,\n",
    "    bucket_size=bucket_size,\n",
    "    causal = False,\n",
    "    use_full_attn = False,\n",
    "    fixed_position_emb = False,\n",
    "    n_hashes = 4,\n",
    ")\n",
    "model.token_emb = nn.Linear(1,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classiformer(dim, depth, heads, lsh_dropout, bucket_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky_loss(logits, true, alpha, beta, eps=1e-7):\n",
    "    \"\"\"Computes the Tversky loss [1].\n",
    "    Args:\n",
    "        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        alpha: controls the penalty for false positives.\n",
    "        beta: controls the penalty for false negatives.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        tversky_loss: the Tversky loss.\n",
    "    Notes:\n",
    "        alpha = beta = 0.5 => dice coeff\n",
    "        alpha = beta = 1 => tanimoto coeff\n",
    "        alpha + beta = 1 => F beta coeff\n",
    "    References:\n",
    "        [1]: https://arxiv.org/abs/1706.05721\n",
    "    \"\"\"\n",
    "    logits = logits.permute(0,2,1).unsqueeze(-1)\n",
    "    true = true.unsqueeze(-1)\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    fps = torch.sum(probas * (1 - true_1_hot), dims)\n",
    "    fns = torch.sum((1 - probas) * true_1_hot, dims)\n",
    "    num = intersection\n",
    "    denom = intersection + (alpha * fps) + (beta * fns)\n",
    "    tversky_loss = (num / (denom + eps)).mean()\n",
    "    return (1 - tversky_loss)\n",
    "\n",
    "class LabelSmoothingCE(Module):\n",
    "    def __init__(self, eps:float=0.1, reduction='mean'): self.eps,self.reduction = eps,reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        output = output.permute(0,2,1) # => B C S\n",
    "        target = target.squeeze(1)     # => B S\n",
    "        log_preds = F.log_softmax(output, dim=1)\n",
    "        if self.reduction=='sum': loss = -log_preds.sum()\n",
    "        else:\n",
    "            loss = -log_preds.sum(dim=1)\n",
    "            if self.reduction=='mean':  loss = loss.mean()\n",
    "        return loss*self.eps/c + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "    \n",
    "class AwareLabelSmoothingCE(Module):\n",
    "    def __init__(self, eps:float=0.1, reduction='mean'): self.eps,self.reduction = eps,reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        output = output.permute(0,2,1) # => B C S\n",
    "        t_one_hot = torch.zeros(target.shape[0],11,target.shape[2],device=target.device).scatter_(1,target, 1.)\n",
    "        t_one_hot = t_one_hot.sum(dim=(2,)) > 0. # B C true for classes present in batch\n",
    "        t_c_per_batch =  t_one_hot.sum(dim=(1,)).float() # B 1 number of classes in each batch\n",
    "        target = target.squeeze(1)     # => B S\n",
    "        log_preds = F.log_softmax(output, dim=1) # B C S\n",
    "        #print(log_preds.shape,t_one_hot.shape,t_c_per_batch.shape)\n",
    "        #print(log_preds[:2],t_one_hot[:2],t_c_per_batch[:2])\n",
    "        if self.reduction=='sum': \n",
    "            loss = -log_preds.sum()\n",
    "            assert False\n",
    "        else:\n",
    "            loss = (-log_preds*t_one_hot.unsqueeze(-1)/t_c_per_batch.view(-1,1,1)).sum(dim=1) # B C S x B C 1 x B 1 \n",
    "            if self.reduction=='mean':  loss = loss.mean()\n",
    "        return loss*self.eps + (1-self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "\n",
    "class DriftChannelsLoss(Module):\n",
    "    def __init__(self):\n",
    "        self.drift_loss = MSELossFlat()\n",
    "        self.open_channels_loss_softf1 = partial(tversky_loss, alpha=0.5,beta=0.5) \n",
    "        self.open_channels_loss_ce     = LabelSmoothingCE() #CrossEntropyLossFlat() #LabelSmoothingCE()# CrossEntropyLossFlat()\n",
    "    def __call__(self, input:Tensor, target:Tensor, **kwargs):\n",
    "        i_drift,i_open_channels = input\n",
    "        t_drift,t_open_channels = target\n",
    "        return 0.0*self.drift_loss(i_drift, t_drift) + \\\n",
    "            0.*self.open_channels_loss_softf1(i_open_channels, t_open_channels) + \\\n",
    "            1.*self.open_channels_loss_ce(i_open_channels, t_open_channels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "\n",
    "# Cell\n",
    "class OpenChannelsAccumMetric(Metric):\n",
    "    \"Stores predictions and targets on CPU in accumulate to perform final calculations with `func`.\"\n",
    "    def __init__(self, func, dim_argmax=None, sigmoid=False, thresh=None, to_np=False, invert_arg=False,\n",
    "                 flatten=True, **kwargs):\n",
    "        store_attr(self,'func,dim_argmax,sigmoid,thresh,flatten')\n",
    "        self.to_np,self.invert_args,self.kwargs = to_np,invert_arg,kwargs\n",
    "\n",
    "    def reset(self): self.targs,self.preds = [],[]\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        t,p = learn.y[1],learn.pred[1]\n",
    "        pred = p.argmax(dim=self.dim_argmax) if self.dim_argmax else p\n",
    "        if self.sigmoid: pred = torch.sigmoid(pred)\n",
    "        if self.thresh:  pred = (pred >= self.thresh)\n",
    "        #pred = p.round()\n",
    "        targ = t\n",
    "        pred,targ = to_detach(pred),to_detach(targ)\n",
    "        if self.flatten: pred,targ = flatten_check(pred,targ)\n",
    "        self.preds.append(pred)\n",
    "        self.targs.append(targ)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.preds) == 0: return\n",
    "        preds,targs = torch.cat(self.preds),torch.cat(self.targs)\n",
    "        if self.to_np: preds,targs = preds.numpy(),targs.numpy()\n",
    "        return self.func(targs, preds, **self.kwargs) if self.invert_args else self.func(preds, targs, **self.kwargs)\n",
    "\n",
    "    @property\n",
    "    def name(self):  return self.func.func.__name__ if hasattr(self.func, 'func') else  self.func.__name__\n",
    "\n",
    "# Cell\n",
    "def skm_to__open_channels_fastai(func, is_class=True, thresh=None, axis=-1, sigmoid=None, **kwargs):\n",
    "    \"Convert `func` from sklearn.metrics to a fastai metric\"\n",
    "    dim_argmax = axis if is_class and thresh is None else None\n",
    "    sigmoid = sigmoid if sigmoid is not None else (is_class and thresh is not None)\n",
    "    return OpenChannelsAccumMetric(func, dim_argmax=dim_argmax, sigmoid=sigmoid, thresh=thresh,\n",
    "                       to_np=True, invert_arg=True, **kwargs)\n",
    "\n",
    "def F1Score(axis=-1, labels=None, pos_label=1, average='binary', sample_weight=None):\n",
    "    \"F1 score for single-label classification problems\"\n",
    "    return skm_to__open_channels_fastai(skm.f1_score, axis=axis,\n",
    "                         labels=labels, pos_label=pos_label, average=average, sample_weight=sample_weight)\n",
    "\n",
    "def accuracy(inp, targ, axis=-1):\n",
    "    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n",
    "    pred,targ = inp[1], targ[1]\n",
    "    pred,targ = flatten_check(pred.argmax(dim=axis), targ)\n",
    "    return (pred == targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = None\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "learn = Learner(dls,model,loss_func=DriftChannelsLoss(),opt_func=Adam,\n",
    "                metrics=[F1Score(labels=list(range(11)),average='macro'), accuracy])\n",
    "learn.to_parallel().to_fp16()\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('ref_256_4_4_50_0.1_64_400_cv0.9293_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_min, lr_steep=learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 03:01<12:04]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.223913</td>\n",
       "      <td>1.280377</td>\n",
       "      <td>0.395723</td>\n",
       "      <td>0.568312</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.855124</td>\n",
       "      <td>1.015538</td>\n",
       "      <td>0.512022</td>\n",
       "      <td>0.738810</td>\n",
       "      <td>01:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='166' class='' max='211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      78.67% [166/211 01:04<00:17 1.1859]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10,lr_max=5e-4)#,pct_start=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv,_,time = learn.recorder.log[-3:];cv,_,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = f'ref_{dim}_{depth}_{heads}_{bucket_size}_{lsh_dropout}_{BS}_{WINDOW_SIZE}_cv{cv:0.04f}{DATA_SUFFIX}'\n",
    "learn.save(modelname);modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.model=learn.model.module#.module.module.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.eval()\n",
    "test_preds = torch.zeros(test[0].numel(),11,dtype=torch.float)\n",
    "with torch.no_grad():\n",
    "    for flip in [True,False]:\n",
    "        for i,x in enumerate(progress_bar(test_dl)):\n",
    "            if flip: x[0] = torch.flip(x[0], dims=(2,))\n",
    "            preds = learn.model(x[0])\n",
    "            open_channels = preds[1]\n",
    "            if flip: open_channels = torch.flip(open_channels, dims=(1,))\n",
    "            test_preds[i*WINDOW_SIZE*BS:(i+1)*WINDOW_SIZE*BS] += open_channels.view(-1,11).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_channels = test_preds.argmax(dim=1) # torch.clamp(test_preds.round(),0,10).int().squeeze()#.item() #\n",
    "open_channels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(open_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(open_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fname = f'{modelname}.csv';csv_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv_path = p_input / 'sample_submission.csv'\n",
    "ss = pd.read_csv(submission_csv_path, dtype={'time': str})\n",
    "test_preds_all = test_preds\n",
    "test_pred_frame = pd.DataFrame({'time': ss['time'].astype(str), 'open_channels': open_channels})\n",
    "test_pred_frame.to_csv(csv_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c 'liverpool-ion-switching' -f {csv_fname} -m 'trans 1 feat jitter flip=0.5 20 epochs flip_tta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
